---
title: "Kaggle Data Science Survey 2019 - Clean and SQL Upload"
author: "Jeff Shamp"
date: "`r Sys.Date()`"
output:
  prettydoc::html_pretty:
    theme: architect
    highlight: vignette
---

# Kaggle Data Science uSrvery 2019 - Clean and Upload to SQL

## Appendix

This is additional information for server uploads. The main SQL server upload is published to Rpubs.

Below is the cleaning and organization of the Kaggle Data Science Survey for upload to a SQL server hosted on GCP.

```{r, include=FALSE}
library(tidyr)
library(dplyr)
library(dbplyr)
library(ggplot2)
library(RCurl)
library(RMySQL)
library(stringr)
library(fastDummies)
library(DBI)
```

Connect to server

```{r db-authenticate, echo=T, message=F, Warning=F, eval=F}
conn <-                 # Create a connection to your SQL server
    dbConnect(
      MySQL(),
      username = "root",
      password = rstudioapi::askForPassword("Database password"),
      # For rmd on github use: rstudioapi
      # For knitting use password$pwd
      host = '34.68.193.229'
    )
# Create a DB using a SQL query. 
#dbSendQuery(conn, "CREATE DATABASE Kaggle_DS_survey;")  
```

Load in original data file

```{r}
file<- "Data/multiple_choice_responses.csv"
df<-read.csv(file = file,sep = ",", stringsAsFactors = F, na.strings =T)%>% 
  mutate_if(is.character, list(~na_if(.,""))) 
row_1 <- df[1,]
df2 <- df[2:nrow(df),] %>% filter(Q5 == 'Data Scientist')
df <- rbind(row_1, df2)
```


```{r}
df_basic<- df %>%
  select(Q1:Q2,Q3:Q4,Q6:Q8, Q10,Q11,Q15) %>%
  rename(age = Q1,         # custom name for columns
         gender = Q2, 
         country = Q3,
         education = Q4,
         company_size = Q6,
         ds_team_size = Q7,
         company_use_ml = Q8,
         compensation_USD = Q10,
         spend_ml_cloud_work_USD = Q11,
         code_exp_years = Q15) %>%
  slice(2:(dim(df)[1])) %>%
  mutate(                  # Following mutatations to clean formatting
    country = str_replace_all(country,
                "United Kingdom of Great Britain and Northern Ireland",
                "United Kingdom")) %>%
  mutate(country = str_replace_all(country, "Iran, Islamic Republic of...", "Iran")) %>%
  mutate(company_size = str_remove_all(company_size, "employees")) %>%
  mutate(education = str_remove_all(education, "degree")) %>%
  mutate(education = str_remove_all(education, "[:punct:]")) %>%
  mutate(compensation_USD = str_remove_all(compensation_USD, "[$]")) %>%
  mutate(spend_ml_cloud_work_USD = str_remove_all(spend_ml_cloud_work_USD,"[$]")) %>%
  mutate(spend_ml_cloud_work_USD = str_remove_all(spend_ml_cloud_work_USD,"\\(USD\\)")) %>%
  mutate(code_exp_years= str_remove_all(code_exp_years, "years")) %>%
  mutate(code_exp_years= str_replace_all(code_exp_years, "I have never written code", "None"))
df_basic$id <- 1:nrow(df_basic)
write_table = FALSE
if (write_table == TRUE){
 dbSendQuery(conn, "USE Kaggle_DS_survey;")
 dbWriteTable(conn = conn, name = "df_basic", value = df_basic)
}
```

Renaming function


```{r}
rename.columns<- function(df){
items<- rep(NA, dim(df)[2])
for (i in 1:ncol(df)){
  items[i]<- str_extract(df[1,i], "[-].*")
  items[i]<- str_remove(items[i], "- Selected Choice -  |- Selected Choice -")
  items[i]<- str_remove(items[i], "\\(.*\\)")
  items[i]<- str_replace(items[i], "[:punct:]\\s", "")
  items[i]<- str_remove_all(items[i], "\\s$|^\\s")
  items[i]<- str_replace_all(items[i], "\\s", "_")
  items[i]<- str_remove(items[i], "_$")
  names(df)[names(df) == names(df[i])]<-items[i]
}
df<- df %>% slice(2:dim(df)[1])
df$id <- 1:nrow(df)
df[is.na(df)] <- 0
return(df)
}
```

Clean other tables for upload.

```{r}
write_table = FALSE

# Primary Tool for DA at school/work
df_prime_tool<- df %>% 
  select(Q14 )%>%
  slice(2:dim(df)[1]) %>%
  rename(primary_analysis_tool = Q14)
df_prime_tool$id <- 1:nrow(df_prime_tool)
df_prime_tool[is.na(df_prime_tool)] <- 0
if (write_table == TRUE){
 dbSendQuery(conn, "USE Kaggle_DS_survey;")  
 dbWriteTable(conn = conn, name = "df_prime_tool", value = df_prime_tool)
}

# ML year EXP
df_ml_xp<- df %>% select(Q23) %>%
  slice(2:dim(df)[1]) %>%
  rename(ml_exp_years = Q23) %>%
  mutate(ml_exp_years = str_remove_all(ml_exp_years, "years"))
df_ml_xp$id <- 1:nrow(df_ml_xp)
df_ml_xp[is.na(df_ml_xp)] <- 0
if (write_table == TRUE){
 dbSendQuery(conn, "USE Kaggle_DS_survey;")  
 dbWriteTable(conn = conn, name = "df_ml_xp", value = df_ml_xp)
}

# language to learn first?
df_lang_rec<- df%>% 
  select(Q19) %>%
  slice(2:dim(df)[1]) %>%
  rename(rec_lang = Q19)
df_lang_rec$id <- 1:nrow(df_lang_rec)
df_lang_rec[is.na(df_lang_rec)] <- 0
if (write_table == TRUE){
 dbSendQuery(conn, "USE Kaggle_DS_survey;")  
 dbWriteTable(conn = conn, name = "df_lang_rec", value = df_lang_rec)
}

#media sources for DS
df_media<- df %>% select(Q12_Part_1:Q12_Part_12) %>%
  slice(2:dim(df)[1]) %>%
  rename(twiter = Q12_Part_1,
         hacker_news = Q12_Part_2,
         reddit = Q12_Part_3,
         kaggle = Q12_Part_4,
         course_forums = Q12_Part_5,
         you_tube = Q12_Part_6,
         podcast = Q12_Part_7,
         blogs = Q12_Part_8,
         journals = Q12_Part_9,
         slack_communities = Q12_Part_10,
         none = Q12_Part_11,
         other = Q12_Part_12)
df_media$id <- 1:nrow(df_media)
df_media[is.na(df_media)] <- 0
if (write_table == TRUE){
 dbSendQuery(conn, "USE Kaggle_DS_survey;")  
 dbWriteTable(conn = conn, name = "df_media", value = df_media)
}

# DS course work including University
df_online_ed<- df %>% 
  select(Q13_Part_1:Q13_Part_12) 
df_online_ed<- rename.columns(df_online_ed) 
if (write_table == TRUE){
 dbSendQuery(conn, "USE Kaggle_DS_survey;")  
 dbWriteTable(conn = conn, name = "df_online_ed", value = df_online_ed)
}

# IDE
df_ide <- df %>% 
  select(Q16_Part_1:Q16_Part_12) 
df_ide<-rename.columns(df_ide)
if (write_table == TRUE){
 dbSendQuery(conn, "USE Kaggle_DS_survey;")  
 dbWriteTable(conn = conn, name = "df_ide", value = df_ide)
}

# language
df_lang<- df %>%
  select(Q18_Part_1:Q18_Part_12) 
df_lang<- rename.columns(df_lang)
if (write_table == TRUE){
 dbSendQuery(conn, "USE Kaggle_DS_survey;")  
 dbWriteTable(conn = conn, name = "df_lang", value = df_lang)
}

# data viz
df_viz <- df %>% 
  select(Q20_Part_1:Q20_Part_12) 
df_viz<- rename.columns(df_viz) 
if (write_table == TRUE){
 dbSendQuery(conn, "USE Kaggle_DS_survey;")  
 dbWriteTable(conn = conn, name = "df_viz", value = df_viz)
}

# ML algo used regualrly
df_ml_algo<- df %>%select(Q24_Part_1:Q24_Part_12) 
df_ml_algo<-rename.columns(df_ml_algo)
if (write_table == TRUE){
 dbSendQuery(conn, "USE Kaggle_DS_survey;")  
 dbWriteTable(conn = conn, name = "df_ml_algo", value = df_ml_algo)
}

# ML Tools (e.g. AutoML)
df_ml_tool<- df %>% select(Q25_Part_1:Q25_Part_8) 
df_ml_tool<- rename.columns(df_ml_tool) 
if (write_table == TRUE){
 dbSendQuery(conn, "USE Kaggle_DS_survey;")  
 dbWriteTable(conn = conn, name = "df_ml_tool", value = df_ml_tool)
}

# CV tools
df_cv<- df %>% select(Q26_Part_1:Q26_Part_7)
df_cv<-rename.columns(df_cv)
if (write_table == TRUE){
 dbSendQuery(conn, "USE Kaggle_DS_survey;")  
 dbWriteTable(conn = conn, name = "df_cv", value = df_cv)
}

# NLP tools
df_nlp<- df %>% select(Q27_Part_1:Q27_Part_6)
df_nlp<- rename.columns(df_nlp)
if (write_table == TRUE){
 dbSendQuery(conn, "USE Kaggle_DS_survey;")  
 dbWriteTable(conn = conn, name = "df_nlp", value = df_nlp)
}

# Cloud platform
df_cloud<- df %>% select(Q29_Part_1:Q29_Part_12)
df_cloud<- rename.columns(df_cloud)
if (write_table == TRUE){
 dbSendQuery(conn, "USE Kaggle_DS_survey;")  
 dbWriteTable(conn = conn, name = "df_cloud", value = df_cloud)
}

# cloud products
df_cloud_prod<- df %>% select(Q30_Part_1:Q30_Part_12)
df_cloud_prod<- rename.columns(df_cloud_prod)
if (write_table == TRUE){
 dbSendQuery(conn, "USE Kaggle_DS_survey;")  
 dbWriteTable(conn = conn, name = "df_cloud_prod", value = df_cloud_prod)
}

# big data platform
df_big_data<- df %>%select(Q31_Part_1:Q31_Part_12)
df_big_data<- rename.columns(df_big_data)
if (write_table == TRUE){
 dbSendQuery(conn, "USE Kaggle_DS_survey;")  
 dbWriteTable(conn = conn, name = "df_big_data", value = df_big_data)
}

# cloud ML (e.g. Sagemaker)
df_cloud_ml<- df %>% select(Q32_Part_1:Q32_Part_12)
df_cloud_ml<- rename.columns(df_cloud_ml)
if (write_table == TRUE){
 dbSendQuery(conn, "USE Kaggle_DS_survey;")  
 dbWriteTable(conn = conn, name = "df_cloud_ml", value = df_cloud_ml)
}

# relational DB
df_db<- df %>% select(Q34_Part_1:Q34_Part_12)
df_db<- rename.columns(df_db)
if (write_table == TRUE){
 dbSendQuery(conn, "USE Kaggle_DS_survey;")  
 dbWriteTable(conn = conn, name = "df_db", value = df_db)
}
```

```{r}
df_list <- list(df_ml_xp, df_prime_tool, df_lang_rec,df_media, df_online_ed, df_ide, df_lang, df_viz, df_ml_algo, df_ml_tool, df_cv, df_nlp, df_cloud, df_cloud_prod, df_big_data, df_cloud_ml, df_db)
```

Clean and upload for K means analysis. 

```{r}
clean_numeric_bins <- function(series){
  series <- str_remove_all(series, '[,><+/s]') %>%  str_split('-')
  series <- sapply(series, as.integer) %>% sapply(mean) %>% sapply(round)
  series
}

df_basic$compensation_USD <- clean_numeric_bins(df_basic$compensation_USD)
```

Write the dattaframe for K means and send to cloud. 

```{r}
write_table=FALSE
drops <- c("None", "Other","Id")
df_complete<- do.call("cbind", df_list)
colnames(df_complete)<- str_to_title(names(df_complete))
df_complete<- df_complete[,!names(df_complete) %in% drops]
df_complete$id = 1:nrow(df_complete)
df_complete<- df_basic %>%
                inner_join(df_complete, by="id")

df_complete<-df_complete %>%
                filter(country == "United States of America") %>%
                select(!country & !id)

if (write_table == TRUE){
 dbSendQuery(conn, "USE Kaggle_DS_survey;")  
 dbWriteTable(conn = conn, name = "df_complete", value = df_complete)
}

```

Combining data tables and converting the text based answers into categorical dummy variables for KMeans. 


```{r}
df_complete_cat<-df_complete %>% select(!row_names)
df_complete_cat<-dummy_cols(df_complete_cat, remove_first_dummy = T)

df_complete_cat<-df_complete_cat[ ,(ncol(df_complete)+1):ncol(df_complete_cat)]
df_complete_cat[is.na(df_complete_cat)]<--1
```


df_complete_cat will go into the kmeans algorthim for analysis. 








